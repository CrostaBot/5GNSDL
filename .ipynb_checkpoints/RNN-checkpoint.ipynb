{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28117743919</td>\n",
       "      <td>14795251404</td>\n",
       "      <td>554516117</td>\n",
       "      <td>554516117</td>\n",
       "      <td>283582751</td>\n",
       "      <td>283582751</td>\n",
       "      <td>309281138</td>\n",
       "      <td>309281138</td>\n",
       "      <td>510198997</td>\n",
       "      <td>510198997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20770874747</td>\n",
       "      <td>14861950737</td>\n",
       "      <td>356651609</td>\n",
       "      <td>356651609</td>\n",
       "      <td>171192622</td>\n",
       "      <td>171192622</td>\n",
       "      <td>184772992</td>\n",
       "      <td>184772992</td>\n",
       "      <td>434882514</td>\n",
       "      <td>434882514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23606236854</td>\n",
       "      <td>15157164898</td>\n",
       "      <td>696147389</td>\n",
       "      <td>696147389</td>\n",
       "      <td>359746429</td>\n",
       "      <td>359746429</td>\n",
       "      <td>327626158</td>\n",
       "      <td>327626158</td>\n",
       "      <td>494508402</td>\n",
       "      <td>494508402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15730217253</td>\n",
       "      <td>14679307596</td>\n",
       "      <td>467684314</td>\n",
       "      <td>467684314</td>\n",
       "      <td>190005210</td>\n",
       "      <td>190005210</td>\n",
       "      <td>184524533</td>\n",
       "      <td>184524533</td>\n",
       "      <td>383508402</td>\n",
       "      <td>383508402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0                0            0          0           0          0          0   \n",
       "1      28117743919  14795251404  554516117   554516117  283582751  283582751   \n",
       "2      20770874747  14861950737  356651609   356651609  171192622  171192622   \n",
       "3      23606236854  15157164898  696147389   696147389  359746429  359746429   \n",
       "4      15730217253  14679307596  467684314   467684314  190005210  190005210   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0              0          0          0           0  \n",
       "1      309281138  309281138  510198997   510198997  \n",
       "2      184772992  184772992  434882514   434882514  \n",
       "3      327626158  327626158  494508402   494508402  \n",
       "4      184524533  184524533  383508402   383508402  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5704816  0.00588964 0.01030665 0.01159854 0.01008111]\n",
      "[0.57038559 0.00513615 0.00749913 0.00811517 0.007527  ]\n",
      "[0.65365404 0.02437584 0.01922711 0.01718993 0.02663473]\n",
      "[0.73396538 0.02338422 0.00950026 0.00922623 0.01917542]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[28117743919,554516117,283582751,309281138,510198997]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
