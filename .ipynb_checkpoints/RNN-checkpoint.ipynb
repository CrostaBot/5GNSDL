{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18200421985</td>\n",
       "      <td>13565782190</td>\n",
       "      <td>463613841</td>\n",
       "      <td>463613841</td>\n",
       "      <td>213294893</td>\n",
       "      <td>213294893</td>\n",
       "      <td>229638555</td>\n",
       "      <td>229638555</td>\n",
       "      <td>418040584</td>\n",
       "      <td>418040584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12833389832</td>\n",
       "      <td>12833389832</td>\n",
       "      <td>250468052</td>\n",
       "      <td>250468052</td>\n",
       "      <td>64060997</td>\n",
       "      <td>64060997</td>\n",
       "      <td>84341210</td>\n",
       "      <td>84341210</td>\n",
       "      <td>383708488</td>\n",
       "      <td>383708488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38911337285</td>\n",
       "      <td>14852658085</td>\n",
       "      <td>719455455</td>\n",
       "      <td>719455455</td>\n",
       "      <td>343823691</td>\n",
       "      <td>343823691</td>\n",
       "      <td>309254926</td>\n",
       "      <td>309254926</td>\n",
       "      <td>721374614</td>\n",
       "      <td>721374614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35520744282</td>\n",
       "      <td>15144713938</td>\n",
       "      <td>282404961</td>\n",
       "      <td>282404961</td>\n",
       "      <td>150756074</td>\n",
       "      <td>150756074</td>\n",
       "      <td>145188335</td>\n",
       "      <td>145188335</td>\n",
       "      <td>640802011</td>\n",
       "      <td>640802011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0                0            0          0           0          0          0   \n",
       "1      18200421985  13565782190  463613841   463613841  213294893  213294893   \n",
       "2      12833389832  12833389832  250468052   250468052   64060997   64060997   \n",
       "3      38911337285  14852658085  719455455   719455455  343823691  343823691   \n",
       "4      35520744282  15144713938  282404961   282404961  150756074  150756074   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0              0          0          0           0  \n",
       "1      229638555  229638555  418040584   418040584  \n",
       "2       84341210   84341210  383708488   383708488  \n",
       "3      309254926  309254926  721374614   721374614  \n",
       "4      145188335  145188335  640802011   640802011  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 4\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0146 - val_loss: 0.0141\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0119 - val_loss: 0.0131\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0108 - val_loss: 0.0129\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6775111  0.0155057  0.00769728 0.00686626 0.01148482]\n",
      "[0.68874126 0.01199011 0.00576974 0.0064712  0.00904236]\n",
      "[0.73827255 0.01600475 0.00820625 0.00656047 0.01378893]\n",
      "[0.7572357  0.01412025 0.0075378  0.00725942 0.0320401 ]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[29134251061,187609472,194216024,110492056,439310873]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
