{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14135738986</td>\n",
       "      <td>14135738986</td>\n",
       "      <td>183636064</td>\n",
       "      <td>183636064</td>\n",
       "      <td>132047432</td>\n",
       "      <td>132047432</td>\n",
       "      <td>174948154</td>\n",
       "      <td>174948154</td>\n",
       "      <td>256599799</td>\n",
       "      <td>256599799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41280858627</td>\n",
       "      <td>17850282270</td>\n",
       "      <td>329891717</td>\n",
       "      <td>329891717</td>\n",
       "      <td>285377529</td>\n",
       "      <td>285377529</td>\n",
       "      <td>369429583</td>\n",
       "      <td>369429583</td>\n",
       "      <td>649253798</td>\n",
       "      <td>632765102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38436413381</td>\n",
       "      <td>18163677631</td>\n",
       "      <td>321798499</td>\n",
       "      <td>321798499</td>\n",
       "      <td>183000490</td>\n",
       "      <td>183000490</td>\n",
       "      <td>211807759</td>\n",
       "      <td>211807759</td>\n",
       "      <td>617741942</td>\n",
       "      <td>617325258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35012592777</td>\n",
       "      <td>17970187108</td>\n",
       "      <td>283394642</td>\n",
       "      <td>283394642</td>\n",
       "      <td>318840447</td>\n",
       "      <td>318840447</td>\n",
       "      <td>388482214</td>\n",
       "      <td>388482214</td>\n",
       "      <td>554585090</td>\n",
       "      <td>553071014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0                0            0          0           0          0          0   \n",
       "1      14135738986  14135738986  183636064   183636064  132047432  132047432   \n",
       "2      41280858627  17850282270  329891717   329891717  285377529  285377529   \n",
       "3      38436413381  18163677631  321798499   321798499  183000490  183000490   \n",
       "4      35012592777  17970187108  283394642   283394642  318840447  318840447   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0              0          0          0           0  \n",
       "1      174948154  174948154  256599799   256599799  \n",
       "2      369429583  369429583  649253798   632765102  \n",
       "3      211807759  211807759  617741942   617325258  \n",
       "4      388482214  388482214  554585090   553071014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0269 - val_loss: 0.0287\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0276\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0232 - val_loss: 0.0287\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0229 - val_loss: 0.0277\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0228 - val_loss: 0.0268\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0226 - val_loss: 0.0272\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0225 - val_loss: 0.0280\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0224 - val_loss: 0.0268\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0223 - val_loss: 0.0275\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0222 - val_loss: 0.0262\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0221 - val_loss: 0.0269\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0221 - val_loss: 0.0266\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0220 - val_loss: 0.0261\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0219 - val_loss: 0.0260\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0218 - val_loss: 0.0270\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0218 - val_loss: 0.0268\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0217 - val_loss: 0.0282\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0217 - val_loss: 0.0255\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0217 - val_loss: 0.0289\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0217 - val_loss: 0.0272\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88226527 0.01002413 0.00731078 0.0102368  0.01273997]\n",
      "[0.76252162 0.00797926 0.00862973 0.00942115 0.00949748]\n",
      "[0.9038942  0.00976555 0.00725922 0.00992475 0.01576033]\n",
      "[0.89850936 0.01416973 0.01594202 0.01942411 0.02765355]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[29134251061,187609472,194216024,110492056,439310873]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
