{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43416984823</td>\n",
       "      <td>17392987032</td>\n",
       "      <td>662474056</td>\n",
       "      <td>662474056</td>\n",
       "      <td>341195262</td>\n",
       "      <td>341195262</td>\n",
       "      <td>349262371</td>\n",
       "      <td>349262371</td>\n",
       "      <td>597551580</td>\n",
       "      <td>597551580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67809055201</td>\n",
       "      <td>17761759260</td>\n",
       "      <td>551875687</td>\n",
       "      <td>551875687</td>\n",
       "      <td>298211255</td>\n",
       "      <td>298211255</td>\n",
       "      <td>370954027</td>\n",
       "      <td>370954027</td>\n",
       "      <td>951136126</td>\n",
       "      <td>951136126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67756318810</td>\n",
       "      <td>17713912304</td>\n",
       "      <td>609694449</td>\n",
       "      <td>609694449</td>\n",
       "      <td>336192886</td>\n",
       "      <td>336192886</td>\n",
       "      <td>289397074</td>\n",
       "      <td>289397074</td>\n",
       "      <td>920173016</td>\n",
       "      <td>920173016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57100587829</td>\n",
       "      <td>18946544273</td>\n",
       "      <td>30189256</td>\n",
       "      <td>30189256</td>\n",
       "      <td>42895685</td>\n",
       "      <td>42895685</td>\n",
       "      <td>48573808</td>\n",
       "      <td>48573808</td>\n",
       "      <td>722280280</td>\n",
       "      <td>722280280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46781070284</td>\n",
       "      <td>18530565474</td>\n",
       "      <td>194927480</td>\n",
       "      <td>194927480</td>\n",
       "      <td>120669539</td>\n",
       "      <td>120669539</td>\n",
       "      <td>135742773</td>\n",
       "      <td>135742773</td>\n",
       "      <td>518151162</td>\n",
       "      <td>518151162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0      43416984823  17392987032  662474056   662474056  341195262  341195262   \n",
       "1      67809055201  17761759260  551875687   551875687  298211255  298211255   \n",
       "2      67756318810  17713912304  609694449   609694449  336192886  336192886   \n",
       "3      57100587829  18946544273   30189256    30189256   42895685   42895685   \n",
       "4      46781070284  18530565474  194927480   194927480  120669539  120669539   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0      349262371  349262371  597551580   597551580  \n",
       "1      370954027  370954027  951136126   951136126  \n",
       "2      289397074  289397074  920173016   920173016  \n",
       "3       48573808   48573808  722280280   722280280  \n",
       "4      135742773  135742773  518151162   518151162  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0189 - val_loss: 0.0150\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0159 - val_loss: 0.0128\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0158 - val_loss: 0.0136\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0158 - val_loss: 0.0124\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0158 - val_loss: 0.0131\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0157 - val_loss: 0.0132\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0157 - val_loss: 0.0138\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63437986 0.01657911 0.00797648 0.00768435 0.01096512]\n",
      "[0.5927385  0.00791548 0.00411664 0.00366136 0.0112927 ]\n",
      "[0.76417774 0.00996409 0.00489848 0.0038805  0.01849279]\n",
      "[0.92652827 0.00974637 0.00603348 0.00678714 0.02590756]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[28117743919, 554516117, 283582751, 309281138, 510198997]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
