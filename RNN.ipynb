{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51226744105</td>\n",
       "      <td>17058139939</td>\n",
       "      <td>879928209</td>\n",
       "      <td>879661334</td>\n",
       "      <td>437113589</td>\n",
       "      <td>437113589</td>\n",
       "      <td>457663395</td>\n",
       "      <td>457663395</td>\n",
       "      <td>701451983</td>\n",
       "      <td>553419347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62842626119</td>\n",
       "      <td>17986755349</td>\n",
       "      <td>427024666</td>\n",
       "      <td>427024666</td>\n",
       "      <td>217247624</td>\n",
       "      <td>217247624</td>\n",
       "      <td>232419725</td>\n",
       "      <td>232419725</td>\n",
       "      <td>1047830240</td>\n",
       "      <td>1045461045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57634824438</td>\n",
       "      <td>17209956752</td>\n",
       "      <td>634799444</td>\n",
       "      <td>634799444</td>\n",
       "      <td>357482882</td>\n",
       "      <td>357482882</td>\n",
       "      <td>448397177</td>\n",
       "      <td>448397177</td>\n",
       "      <td>915236773</td>\n",
       "      <td>642126921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50119284098</td>\n",
       "      <td>18286733290</td>\n",
       "      <td>259421011</td>\n",
       "      <td>259421011</td>\n",
       "      <td>102006337</td>\n",
       "      <td>102006337</td>\n",
       "      <td>109405616</td>\n",
       "      <td>109405616</td>\n",
       "      <td>713417381</td>\n",
       "      <td>705298630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47545603314</td>\n",
       "      <td>17339215524</td>\n",
       "      <td>878082456</td>\n",
       "      <td>875081378</td>\n",
       "      <td>418170793</td>\n",
       "      <td>418170793</td>\n",
       "      <td>467163218</td>\n",
       "      <td>467163218</td>\n",
       "      <td>511714488</td>\n",
       "      <td>509569794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0      51226744105  17058139939  879928209   879661334  437113589  437113589   \n",
       "1      62842626119  17986755349  427024666   427024666  217247624  217247624   \n",
       "2      57634824438  17209956752  634799444   634799444  357482882  357482882   \n",
       "3      50119284098  18286733290  259421011   259421011  102006337  102006337   \n",
       "4      47545603314  17339215524  878082456   875081378  418170793  418170793   \n",
       "\n",
       "        mmtc_req  mmtc_true   voice_req  voice_true  \n",
       "round                                                \n",
       "0      457663395  457663395   701451983   553419347  \n",
       "1      232419725  232419725  1047830240  1045461045  \n",
       "2      448397177  448397177   915236773   642126921  \n",
       "3      109405616  109405616   713417381   705298630  \n",
       "4      467163218  467163218   511714488   509569794  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0247 - val_loss: 0.0336\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0212 - val_loss: 0.0336\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0208 - val_loss: 0.0333\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0207 - val_loss: 0.0336\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0205 - val_loss: 0.0331\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0205 - val_loss: 0.0335\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0204 - val_loss: 0.0335\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0204 - val_loss: 0.0337\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0203 - val_loss: 0.0337\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0203 - val_loss: 0.0334\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0203 - val_loss: 0.0337\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0349\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0341\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0338\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0331\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0338\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0331\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0340\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0202 - val_loss: 0.0336\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0201 - val_loss: 0.0334\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92311895 0.00899014 0.0020754  0.00304362 0.0138314 ]\n",
      "[0.93631424 0.01199095 0.00533862 0.00493588 0.01651228]\n",
      "[9.3294024e-01 6.2869899e-03 7.3225424e-04 1.4588470e-03 1.7039511e-02]\n",
      "[0.86696078 0.04375407 0.02090854 0.02335816 0.02547849]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[28117743919, 554516117, 283582751, 309281138, 510198997]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
