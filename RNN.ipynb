{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35881556553</td>\n",
       "      <td>18397231064</td>\n",
       "      <td>310731060</td>\n",
       "      <td>310731060</td>\n",
       "      <td>268358393</td>\n",
       "      <td>268358393</td>\n",
       "      <td>197834085</td>\n",
       "      <td>197834085</td>\n",
       "      <td>385305779</td>\n",
       "      <td>183233839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34434707268</td>\n",
       "      <td>18820831904</td>\n",
       "      <td>123100573</td>\n",
       "      <td>118688191</td>\n",
       "      <td>98572943</td>\n",
       "      <td>98572943</td>\n",
       "      <td>86678231</td>\n",
       "      <td>86678231</td>\n",
       "      <td>372596872</td>\n",
       "      <td>239177970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70393547201</td>\n",
       "      <td>17662294326</td>\n",
       "      <td>548025869</td>\n",
       "      <td>522263272</td>\n",
       "      <td>457143583</td>\n",
       "      <td>457143583</td>\n",
       "      <td>334637608</td>\n",
       "      <td>334637608</td>\n",
       "      <td>681622354</td>\n",
       "      <td>375623182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62648026006</td>\n",
       "      <td>18790887173</td>\n",
       "      <td>147443942</td>\n",
       "      <td>147443942</td>\n",
       "      <td>110160319</td>\n",
       "      <td>110160319</td>\n",
       "      <td>85408682</td>\n",
       "      <td>85408682</td>\n",
       "      <td>544622354</td>\n",
       "      <td>458477529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0                0            0          0           0          0          0   \n",
       "1      35881556553  18397231064  310731060   310731060  268358393  268358393   \n",
       "2      34434707268  18820831904  123100573   118688191   98572943   98572943   \n",
       "3      70393547201  17662294326  548025869   522263272  457143583  457143583   \n",
       "4      62648026006  18790887173  147443942   147443942  110160319  110160319   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0              0          0          0           0  \n",
       "1      197834085  197834085  385305779   183233839  \n",
       "2       86678231   86678231  372596872   239177970  \n",
       "3      334637608  334637608  681622354   375623182  \n",
       "4       85408682   85408682  544622354   458477529  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 30000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 16 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 30000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 1875 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 750 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 10\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1875 steps, validate for 750 steps\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.0055 - val_loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9523152  0.00701474 0.00612248 0.00920417 0.00857242]\n",
      "[0.93077304 0.01325895 0.01335097 0.00897079 0.01115676]\n",
      "[0.94691247 0.00723898 0.00671243 0.00945676 0.00934454]\n",
      "[0.9410416  0.00593441 0.00492865 0.00433391 0.0119589 ]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[35881556553 , 310731060 , 268358393, 197834085, 385305779]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[0]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9490212  0.00932256 0.00688147 0.00760134 0.01129607]\n",
    "[0.9410416  0.00593441 0.00492865 0.00433391 0.0119589 ] 42 256 32\n",
    "[0.9396471  0.00828853 0.0097623  0.0081543  0.01002839]\n",
    "[0.9410416  0.00593441 0.00492865 0.00433391 0.0119589 ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
