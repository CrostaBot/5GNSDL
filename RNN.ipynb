{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48366352451</td>\n",
       "      <td>14753425662</td>\n",
       "      <td>821443044</td>\n",
       "      <td>821443044</td>\n",
       "      <td>454899066</td>\n",
       "      <td>454899066</td>\n",
       "      <td>412873975</td>\n",
       "      <td>412873975</td>\n",
       "      <td>789671880</td>\n",
       "      <td>789671880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41635005196</td>\n",
       "      <td>15327079419</td>\n",
       "      <td>366694134</td>\n",
       "      <td>366694134</td>\n",
       "      <td>259996062</td>\n",
       "      <td>259996062</td>\n",
       "      <td>184881966</td>\n",
       "      <td>184881966</td>\n",
       "      <td>737354839</td>\n",
       "      <td>737354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33702013813</td>\n",
       "      <td>15105126775</td>\n",
       "      <td>455571105</td>\n",
       "      <td>455571105</td>\n",
       "      <td>255653544</td>\n",
       "      <td>255653544</td>\n",
       "      <td>292088284</td>\n",
       "      <td>292088284</td>\n",
       "      <td>600314013</td>\n",
       "      <td>600314013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33635062725</td>\n",
       "      <td>14973135597</td>\n",
       "      <td>798957171</td>\n",
       "      <td>798957171</td>\n",
       "      <td>422170133</td>\n",
       "      <td>422170133</td>\n",
       "      <td>400555854</td>\n",
       "      <td>400555854</td>\n",
       "      <td>471688801</td>\n",
       "      <td>471688801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0                0            0          0           0          0          0   \n",
       "1      48366352451  14753425662  821443044   821443044  454899066  454899066   \n",
       "2      41635005196  15327079419  366694134   366694134  259996062  259996062   \n",
       "3      33702013813  15105126775  455571105   455571105  255653544  255653544   \n",
       "4      33635062725  14973135597  798957171   798957171  422170133  422170133   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0              0          0          0           0  \n",
       "1      412873975  412873975  789671880   789671880  \n",
       "2      184881966  184881966  737354839   737354839  \n",
       "3      292088284  292088284  600314013   600314013  \n",
       "4      400555854  400555854  471688801   471688801  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0052 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83397067 0.03898463 0.02037413 0.02118398 0.02022251]\n",
      "[0.83236394 0.03206446 0.01918653 0.01900058 0.02111502]\n",
      "[0.8454119  0.03891478 0.02013643 0.02121386 0.02078872]\n",
      "[0.74865678 0.03994786 0.02110851 0.02002779 0.02358444]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[28117743919, 554516117, 283582751, 309281138, 510198997]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
