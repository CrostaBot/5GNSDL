{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embb_req</th>\n",
       "      <th>embb_true</th>\n",
       "      <th>urllc_req</th>\n",
       "      <th>urllc_true</th>\n",
       "      <th>miot_req</th>\n",
       "      <th>miot_true</th>\n",
       "      <th>mmtc_req</th>\n",
       "      <th>mmtc_true</th>\n",
       "      <th>voice_req</th>\n",
       "      <th>voice_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13405922974</td>\n",
       "      <td>13030020496</td>\n",
       "      <td>198602474</td>\n",
       "      <td>198602474</td>\n",
       "      <td>102163362</td>\n",
       "      <td>102163362</td>\n",
       "      <td>54668699</td>\n",
       "      <td>54668699</td>\n",
       "      <td>190728724</td>\n",
       "      <td>190728724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14891822876</td>\n",
       "      <td>13832043931</td>\n",
       "      <td>95467765</td>\n",
       "      <td>95467765</td>\n",
       "      <td>105346529</td>\n",
       "      <td>105346529</td>\n",
       "      <td>67839887</td>\n",
       "      <td>67839887</td>\n",
       "      <td>268679119</td>\n",
       "      <td>268679119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13959637690</td>\n",
       "      <td>13839867790</td>\n",
       "      <td>103193515</td>\n",
       "      <td>103193515</td>\n",
       "      <td>46819034</td>\n",
       "      <td>46819034</td>\n",
       "      <td>59392887</td>\n",
       "      <td>59392887</td>\n",
       "      <td>314980021</td>\n",
       "      <td>314980021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31850806940</td>\n",
       "      <td>14948808304</td>\n",
       "      <td>434672547</td>\n",
       "      <td>434672547</td>\n",
       "      <td>336038788</td>\n",
       "      <td>336038788</td>\n",
       "      <td>221439466</td>\n",
       "      <td>221439466</td>\n",
       "      <td>509947726</td>\n",
       "      <td>509947726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26177130335</td>\n",
       "      <td>15232227585</td>\n",
       "      <td>51288544</td>\n",
       "      <td>51288544</td>\n",
       "      <td>37400967</td>\n",
       "      <td>37400967</td>\n",
       "      <td>25563860</td>\n",
       "      <td>25563860</td>\n",
       "      <td>412911391</td>\n",
       "      <td>412911391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          embb_req    embb_true  urllc_req  urllc_true   miot_req  miot_true  \\\n",
       "round                                                                          \n",
       "0      13405922974  13030020496  198602474   198602474  102163362  102163362   \n",
       "1      14891822876  13832043931   95467765    95467765  105346529  105346529   \n",
       "2      13959637690  13839867790  103193515   103193515   46819034   46819034   \n",
       "3      31850806940  14948808304  434672547   434672547  336038788  336038788   \n",
       "4      26177130335  15232227585   51288544    51288544   37400967   37400967   \n",
       "\n",
       "        mmtc_req  mmtc_true  voice_req  voice_true  \n",
       "round                                               \n",
       "0       54668699   54668699  190728724   190728724  \n",
       "1       67839887   67839887  268679119   268679119  \n",
       "2       59392887   59392887  314980021   314980021  \n",
       "3      221439466  221439466  509947726   509947726  \n",
       "4       25563860   25563860  412911391   412911391  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with panda\n",
    "df = pd.read_csv('output.csv')\n",
    "features_considered = ['embb_req', 'embb_true', 'urllc_req', 'urllc_true','miot_req', 'miot_true','mmtc_req', 'mmtc_true','voice_req', 'voice_true']\n",
    "features = df[features_considered]\n",
    "features.index = df['round']\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametes \n",
    "TRAIN_SPLIT = 64000\n",
    "tf.random.set_seed(13)\n",
    "past_history = 1\n",
    "future_target = 0\n",
    "step = 1\n",
    "BATCH_SIZE = 32 # combines consecutive elements of this dataset into batches.\n",
    "BUFFER_SIZE = 80000 # >= len dataset for perfetct shuffling\n",
    "EVALUATION_INTERVAL = 2000 # steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "VALIDATION_STEPS = 500 # validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "EPOCHS = 20\n",
    "bs_capacity = 20000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "dataset = features.values\n",
    "dataset = dataset / bs_capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "\n",
    "    data.append(dataset[indices])\n",
    "    labels.append(target[i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation and training set\n",
    "x_train, y_train = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], 0, TRAIN_SPLIT, past_history,future_target, step)\n",
    "x_val, y_val = multivariate_data(dataset[1:, (0, 2, 4, 6, 8)], dataset[1:, (1, 3, 5, 7, 9)], TRAIN_SPLIT, None, past_history, future_target, step)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2000 steps, validate for 500 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0257 - val_loss: 0.0237\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0243 - val_loss: 0.0222\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0241 - val_loss: 0.0225\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0240 - val_loss: 0.0236\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0239 - val_loss: 0.0227\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0238 - val_loss: 0.0224\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0238 - val_loss: 0.0248\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0237 - val_loss: 0.0231\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0237 - val_loss: 0.0218\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0237 - val_loss: 0.0246\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0237 - val_loss: 0.0225\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0237 - val_loss: 0.0240\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0237 - val_loss: 0.0225\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0229\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0213\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0215\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0228\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0225\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0236 - val_loss: 0.0224\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=x_train.shape[-2:])) # 4*(len features input * len output + input^2)\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "\n",
    "# Compile RNN\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "\n",
    "# Train RNN\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4033091  0.005623   0.0038313  0.00235694 0.0053687 ]\n",
      "[0.31420964 0.00469123 0.00282344 0.00143392 0.0040093 ]\n",
      "[0.8540199  0.00686314 0.00492667 0.00139339 0.01798228]\n",
      "[0.76161138 0.00256443 0.00187005 0.00127819 0.02064557]\n"
     ]
    }
   ],
   "source": [
    "#Example prediction\n",
    "prediction = model.predict(x_val, batch_size=BATCH_SIZE)[0]\n",
    "\n",
    "print(prediction)\n",
    "print(y_val[0])\n",
    "\n",
    "# Prediction with new input value\n",
    "test = [[[28117743919, 554516117, 283582751, 309281138, 510198997]]]\n",
    "test = np.array(test)/bs_capacity\n",
    "\n",
    "prediction = model.predict(test)\n",
    "print(prediction[0])\n",
    "print(y_train[2]) # because I took the input of the first values in x_train for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
